{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#stdlib\n",
    "import os, ftplib, itertools\n",
    "import datetime as dt\n",
    "#scientific stack\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.interpolate\n",
    "import spacepy.datamodel as dm\n",
    "import spacepy.time as spt\n",
    "import spacepy.pybats as swmf\n",
    "from sklearn.neighbors import KernelDensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_SC_OMNI(year=2000, bird='ACE', datadir='Data', force=False, verbose=False, **kwargs):\n",
    "    '''Download S/C specific OMNI file'''\n",
    "    valid_birds = ['ACE', 'IMP', 'GEOTAIL', 'WIND']\n",
    "    if bird.upper() not in valid_birds:\n",
    "        raise ValueError('Invalid satellite selected ({0})'.format(bird))\n",
    "    targ_fn = '{0}_min_b{1}.txt'.format(bird.lower(), year)\n",
    "    #now check whether we have this file already\n",
    "    if not force and os.path.isfile(os.path.join(datadir, targ_fn)):\n",
    "        if verbose: print('Data already present for {0} in {1} - not downloading'.format(bird, year))\n",
    "        return os.path.join(datadir, targ_fn)\n",
    "    #now download the file and save in datadir\n",
    "    omni_ftp = 'spdf.gsfc.nasa.gov'\n",
    "    sc_dir = 'pub/data/omni/high_res_omni/sc_specific/'\n",
    "    ftp = ftplib.FTP(omni_ftp)\n",
    "    ftp.login()\n",
    "    ftp.cwd(sc_dir)\n",
    "    with open(os.path.join(datadir, targ_fn), 'w') as ofh:\n",
    "        ftp.retrlines('RETR {0}'.format(targ_fn), lambda s, w = ofh.write: w(s + '\\n'))\n",
    "    print('Retrieved {0}'.format(targ_fn))\n",
    "    return os.path.join(datadir, targ_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_SC_OMNI(bird, year, outdata=None, **kwargs):\n",
    "    '''Load satellite specific OMNI data into dict'''\n",
    "    fname = get_SC_OMNI(year=year, bird=bird, **kwargs)\n",
    "    dum = np.genfromtxt(fname, usecols=(0,1,2,3,15,16,23,26,28,29,30), \n",
    "                         names=('year','day','hour','minute','By_GSM','Bz_GSM','Vx_GSE','Den_P','X_GSE','Y_GSE','Z_GSE'),\n",
    "                         converters={0: int, 1: int, 2: int, 3: int})\n",
    "    data = dm.fromRecArray(dum)\n",
    "    dates = spt.doy2date(data['year'], data['day'], dtobj=True)\n",
    "    times = [dt.timedelta(hours=x, minutes=y) for x,y in zip(data['hour'],data['minute'])]\n",
    "    data['DateTime'] = dates + times\n",
    "    for key in ['year', 'day', 'hour', 'minute']:\n",
    "        del data[key]\n",
    "    data['Bz_GSM'][np.abs(data['Bz_GSM'])>20] = np.nan\n",
    "    data['By_GSM'][np.abs(data['By_GSM'])>20] = np.nan\n",
    "    data['Vx_GSE'][np.abs(data['Vx_GSE'])>900] = np.nan\n",
    "    data['X_GSE'][np.abs(data['X_GSE'])>9000] = np.nan\n",
    "    data['Y_GSE'][np.abs(data['Y_GSE'])>9000] = np.nan\n",
    "    data['Z_GSE'][np.abs(data['Z_GSE'])>9000] = np.nan\n",
    "    if outdata:\n",
    "        for key in ['By_GSM', 'Bz_GSM', 'Vx_GSE', 'DateTime', 'Den_P', 'X_GSE', 'Y_GSE', 'Z_GSE']:\n",
    "            outdata[key] = np.concatenate([outdata[key], data[key]])\n",
    "        return outdata\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/smorley/.local/lib/python2.7/site-packages/urllib3/connectionpool.py:857: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    }
   ],
   "source": [
    "#download IMF file from Gist\n",
    "import requests, shutil\n",
    "url = \"https://gist.github.com/drsteve/79a90857b1f6c6cbe2256101ab1202b9\"    #Note: It's https\n",
    "r = requests.get(url, verify=False, stream=True)\n",
    "r.raw.decode_content = True\n",
    "with open(\"IMF_ev5.dat\", 'wb') as f:\n",
    "        shutil.copyfileobj(r.raw, f)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(1234) #set seed for repeatability\n",
    "#read SWMF ImfInput file\n",
    "SWPCeventnum   = 5\n",
    "infilename = 'IMF_ev{}.dat'.format(SWPCeventnum)\n",
    "eventIMF = swmf.ImfInput(filename=infilename)\n",
    "\n",
    "Nensembles     = 80\n",
    "Ntimes         = len(eventIMF['ux']) #3*1440 #N days at 1-min resolution\n",
    "generateInputs = True\n",
    "saveErrors     = False\n",
    "\n",
    "varlist = ['Vx_GSE', 'Bz_GSM', 'By_GSM']\n",
    "Nvars = len(varlist)\n",
    "map_dict = {'Vx_GSE': 'ux',\n",
    "            'Bz_GSM': 'bz',\n",
    "            'By_GSM': 'by'}\n",
    "ylimdict = {'Vx_GSE': [-300, -800],\n",
    "            'Bz_GSM': [-20, 20],\n",
    "            'By_GSM': [-20, 20]}\n",
    "xlimdict = {'Vx_GSE': [-60, 60],\n",
    "            'Bz_GSM': [-15, 15],\n",
    "            'By_GSM': [-15, 15]}\n",
    "unitsdict = {'Vx_GSE': '[km/s]',\n",
    "            'Bz_GSM': '[nT]',\n",
    "            'By_GSM': '[nT]'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load ACE data into dict (ups: upstream)\n",
    "upsdata = load_SC_OMNI('ace', 1999)\n",
    "upsdata = load_SC_OMNI('ace', 2000, outdata=upsdata)\n",
    "upsdata = load_SC_OMNI('ace', 2001, outdata=upsdata)\n",
    "upsdata = load_SC_OMNI('ace', 2002, outdata=upsdata)\n",
    "upsdata = load_SC_OMNI('ace', 2003, outdata=upsdata)\n",
    "upsdata = load_SC_OMNI('ace', 2004, outdata=upsdata)\n",
    "upsdata = load_SC_OMNI('ace', 2005, outdata=upsdata)\n",
    "                                                         \n",
    "#load GEOTAIL data into dict (nmp: near magnetopause)\n",
    "nmpdata = load_SC_OMNI('geotail', 1999)\n",
    "nmpdata = load_SC_OMNI('geotail', 2000, outdata=nmpdata)\n",
    "nmpdata = load_SC_OMNI('geotail', 2001, outdata=nmpdata)\n",
    "nmpdata = load_SC_OMNI('geotail', 2002, outdata=nmpdata)\n",
    "nmpdata = load_SC_OMNI('geotail', 2003, outdata=nmpdata)\n",
    "nmpdata = load_SC_OMNI('geotail', 2004, outdata=nmpdata)\n",
    "nmpdata = load_SC_OMNI('geotail', 2005, outdata=nmpdata)\n",
    "                                                         \n",
    "print(nmpdata['DateTime'][0], nmpdata['DateTime'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "savedata = dm.SpaceData()\n",
    "for var in varlist[::-1]:\n",
    "    print('Processing {}'.format(var))\n",
    "    err = 'epsilon'\n",
    "    varlabel = var[0]+'$_'+var[1]+'$'\n",
    "    errlabel = r'$\\varepsilon$'\n",
    "                                                                                                                      \n",
    "    plotinfo = {'var': var,\n",
    "                'err': err,\n",
    "                'varlabel': varlabel,\n",
    "                'errlabel': errlabel,\n",
    "                'xlimdict': xlimdict,\n",
    "                'ylimdict': ylimdict,\n",
    "                'units': unitsdict}\n",
    "                                                                                                                      \n",
    "    #Get error distrib for var as fn of var and plot\n",
    "    valid_inds = np.logical_and(np.isfinite(nmpdata[var]), np.isfinite(upsdata[var]))\n",
    "    err = nmpdata[var]-upsdata[var]\n",
    "    errors = err[valid_inds]\n",
    "    savedata[var] = errors\n",
    "                                                                                                                      \n",
    "#generate error series with block resampling (cf. moving block bootstrap)\n",
    "#use\n",
    "error_series = np.empty([Nensembles, Ntimes, Nvars])\n",
    "blocksize = 60\n",
    "n_blocks = 1 + Ntimes//blocksize\n",
    "for run_num in range(Nensembles):\n",
    "    #rather than building a 3D array here I should modify an SWMF input file directly\n",
    "    blockstarts = np.random.randint(0, len(errors)-blocksize, n_blocks)\n",
    "    for it, bidx in enumerate(blockstarts):\n",
    "        if Ntimes-it*blocksize>blocksize:\n",
    "            for vidx, var in enumerate(varlist):\n",
    "                error_series[run_num, it*blocksize:it*blocksize+blocksize, vidx] = savedata[var][bidx:bidx+blocksize]\n",
    "        elif Ntimes-it*blocksize>0:\n",
    "            room = len(error_series[run_num, it*blocksize:, vidx])\n",
    "            error_series[run_num, it*blocksize:, vidx] = savedata[var][bidx:bidx+room]\n",
    "        else:\n",
    "            pass\n",
    "    #modify SWMF ImfInput and write new file\n",
    "    outfilename = '.'.join(['_'.join([infilename.split('.')[0],'{0:03d}'.format(run_num)]), 'dat'])\n",
    "    if generateInputs:\n",
    "        surrogateIMF = dm.dmcopy(eventIMF)\n",
    "        for vidx, var in enumerate(varlist):\n",
    "                                                                                                                      \n",
    "            surrogateIMF[map_dict[var]] += error_series[run_num, :Ntimes, vidx]\n",
    "        #then write to file\n",
    "        surrogateIMF.write(outfilename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save error series if req'd\n",
    "if saveErrors:\n",
    "    out = dm.SpaceData()\n",
    "    out['errors'] = dm.dmarray(error_series)\n",
    "    out['errors'].attrs['DEPEND_0'] = 'EnsembleNumber'\n",
    "    out['errors'].attrs['DEPEND_1'] = 'Timestep'\n",
    "    out['errors'].attrs['DEPEND_2'] = 'Variable'\n",
    "    out.toHDF5('MBB_errors.h5'.format(var))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
